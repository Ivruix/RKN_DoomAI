{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28cc1058-4975-4df5-84a5-198c8a640736",
   "metadata": {},
   "source": [
    "## Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c766a99d-9a37-4843-b226-b213e94993bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import csv\n",
    "\n",
    "from typing import Callable, List\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d81add-8b62-4144-85b7-58c338305f84",
   "metadata": {},
   "source": [
    "## Загружаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9b0d0-28bd-4bee-aeca-5b120799e978",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788ebf53-bee5-469a-9799-5fc700efb4b8",
   "metadata": {},
   "source": [
    "## Загружаем векторнуб базу данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9dac9d7-62be-4d63-a3d4-a35fba5ea507",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T06:36:08.867860Z",
     "iopub.status.busy": "2024-11-10T06:36:08.867187Z",
     "iopub.status.idle": "2024-11-10T06:36:08.925806Z",
     "shell.execute_reply": "2024-11-10T06:36:08.924181Z",
     "shell.execute_reply.started": "2024-11-10T06:36:08.867805Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/home/jupyter/datasphere/project/annoy indexes/image_embeddings_256.ann'\n",
    "embedding_dim = 512\n",
    "\n",
    "with open(\"/home/jupyter/datasphere/project/annoy_full/annoy_metadata.json\", 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "index = AnnoyIndex(embedding_dim, 'angular')\n",
    "index.load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d53bfd-d9c8-431e-8dc2-ff71a9fde981",
   "metadata": {},
   "source": [
    "## Оценка тестовых объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee1dd14b-2957-4e63-af91-5829d2acfa7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T06:36:15.929767Z",
     "iopub.status.busy": "2024-11-10T06:36:15.928609Z",
     "iopub.status.idle": "2024-11-10T06:36:15.952728Z",
     "shell.execute_reply": "2024-11-10T06:36:15.951454Z",
     "shell.execute_reply.started": "2024-11-10T06:36:15.929728Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_directory = '/home/jupyter/datasphere/project/TEST_DATASET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "641b7b98-8e62-4266-bd83-4f11dd4a57fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T06:36:16.747242Z",
     "iopub.status.busy": "2024-11-10T06:36:16.746145Z",
     "iopub.status.idle": "2024-11-10T06:36:16.763607Z",
     "shell.execute_reply": "2024-11-10T06:36:16.762296Z",
     "shell.execute_reply.started": "2024-11-10T06:36:16.747187Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "broken_files = ['664e035d-05b3-4766-922c-432dcad827b2.jpg', '1dddee44-7ae9-4a95-8b7d-b0918c62064c.jpg', 'c2232a78-6d52-4e1b-9dc4-dd38d457217c.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f7c6397-0a67-4f62-92dd-bfc3d5f58941",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T06:36:53.473931Z",
     "iopub.status.busy": "2024-11-10T06:36:53.472388Z",
     "iopub.status.idle": "2024-11-10T06:38:37.999017Z",
     "shell.execute_reply": "2024-11-10T06:38:37.997814Z",
     "shell.execute_reply.started": "2024-11-10T06:36:53.473875Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  46%|████▌     | 194/423 [00:50<00:38,  5.99it/s]/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Processing files:  66%|██████▌   | 279/423 [01:11<00:29,  4.82it/s]/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Processing files:  80%|████████  | 340/423 [01:25<00:20,  3.99it/s]/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Processing files: 100%|██████████| 423/423 [01:44<00:00,  4.05it/s]\n"
     ]
    }
   ],
   "source": [
    "k = 10 # количество ближайших соседей\n",
    "\n",
    "item = []\n",
    "predicted = []\n",
    "\n",
    "# Итерация по файлам в директории\n",
    "for dirpath, _, filenames in os.walk(root_directory):\n",
    "    for filename in tqdm(filenames, desc=\"Processing files\"):\n",
    "        \n",
    "        if filename in broken_files:\n",
    "            continue\n",
    "        \n",
    "        item.append(filename)\n",
    "        \n",
    "        # Обработка изображения\n",
    "        file_path = os.path.join(dirpath, filename)\n",
    "        dir_name = os.path.basename(dirpath) \n",
    "        image = Image.open(file_path).convert(\"RGB\")\n",
    "\n",
    "        # Получение векторного представления входного объекта\n",
    "        inputs = processor(images=image, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            image_embedding = model.get_image_features(**inputs)\n",
    "\n",
    "        # Получение k ближайших изображений \n",
    "        image_embedding = image_embedding.cpu().numpy().flatten()\n",
    "        indices = index.get_nns_by_vector(image_embedding, k, search_k=k*256*10)\n",
    "            \n",
    "        # Получение самого популярного класса среди k ближайших изображений\n",
    "        candidat_list = []   \n",
    "        for nn_idx in indices:\n",
    "            nn_metadata_entry = metadata.get(str(nn_idx))\n",
    "            candidat_list.append(nn_metadata_entry['directory'])\n",
    "            \n",
    "        # Назначаем самый популярный класс из топ k\n",
    "        most_common_item = Counter(candidat_list).most_common(1)[0][0]\n",
    "\n",
    "        pred_images = []\n",
    "        selected = 0\n",
    "        \n",
    "        # Получение k ближаших объектов самого популярного класса, которые являются итоговым предсказанием\n",
    "        indices_sort = index.get_nns_by_vector(image_embedding, index.get_n_items(), search_k=k*256*10)\n",
    "        for nn_idx in indices_sort:\n",
    "            nn_metadata_entry = metadata.get(str(nn_idx))\n",
    "            nn_dir = nn_metadata_entry['directory']\n",
    "\n",
    "            if (nn_dir == most_common_item):\n",
    "                nn_filename = nn_metadata_entry['filename']\n",
    "                pred_images.append(nn_filename)\n",
    "                selected += 1\n",
    "                \n",
    "            if selected == k:\n",
    "                break\n",
    "            \n",
    "        predicted.append(pred_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1312dede-40d0-4874-993e-460756218f4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T06:38:52.142451Z",
     "iopub.status.busy": "2024-11-10T06:38:52.140994Z",
     "iopub.status.idle": "2024-11-10T06:38:52.166894Z",
     "shell.execute_reply": "2024-11-10T06:38:52.165611Z",
     "shell.execute_reply.started": "2024-11-10T06:38:52.142380Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('/home/jupyter/datasphere/project/submission/submission.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['image', 'recs']) \n",
    "\n",
    "    for img, recs in zip(item, predicted):\n",
    "        recs_str = ','.join(recs)\n",
    "        writer.writerow([img, f'{recs_str}']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "171f6a0b-c3ed-4c25-a5c2-d64ee2fb9617",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T06:38:52.777680Z",
     "iopub.status.busy": "2024-11-10T06:38:52.776300Z",
     "iopub.status.idle": "2024-11-10T06:38:52.794405Z",
     "shell.execute_reply": "2024-11-10T06:38:52.793109Z",
     "shell.execute_reply.started": "2024-11-10T06:38:52.777643Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3787ec33-fccb-43ec-abff-cb6d4597f64e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
